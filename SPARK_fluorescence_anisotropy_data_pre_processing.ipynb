{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAUqNUxcsevrjtkbjtqMpE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxda6216/SPARK_fluorescence_anisotropy/blob/main/SPARK_fluorescence_anisotropy_data_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p4hs2U34v26m",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "###\n",
        "### This script is to pre-process a SPARK fluorescence anisotropy data file (Excel file).\n",
        "###\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import io\n",
        "import os\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "#@markdown **This script is to pre-process a SPARK fluorescence anisotropy data file (Excel file).**\n",
        "\n",
        "#@markdown This script only works with a specific format of Excel files generated by Tecan SPARK multimode microplate reader. For the data format, please see [GitHub repository page](https://github.com/dxda6216/SPARK_fluorescence_anisotropy).\n",
        "\n",
        "G_factor = 1.000 #@param {type:\"number\"}\n",
        "Plotting_data = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "#@markdown 1. Input G-factor\n",
        "#@markdown 2. **Runtime** -> **Restart and run all** (or press **Ctrl+M** and then press **Ctrl+F9**)\n",
        "#@markdown 3. Wait until `Choose Files` or `Browse...` button appears below.\n",
        "#@markdown 4. Click `Choose Files` or `Browse...` button and select a SPARK Excel data file in your computer.\n",
        "#@markdown 5. Wait a while. Two Excel files, one CSV file, and one ZIP file will be saved in \"Downloads\" folder in your computer.\n",
        "\n",
        "### Deleting old files\n",
        "!rm -f *.xlsx *.csv *.dat *.zip\n",
        "\n",
        "### Uploading an Excel data file\n",
        "uploaded = files.upload()\n",
        "\n",
        "sttime = datetime.now(timezone.utc)\n",
        "processed_dnt_str = sttime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print('\\nStarted at '+processed_dnt_str+' (UTC)')\n",
        "\n",
        "spark_excel_filename = next(iter(uploaded))\n",
        "print('\\n\\\"'+spark_excel_filename+'\\\" has been uploaded.')\n",
        "csv_output_filename = os.path.splitext(spark_excel_filename)[0]+'.csv'\n",
        "csvdatafile = csv_output_filename\n",
        "excel_output_filename = os.path.splitext(spark_excel_filename)[0]+'_SPLITTED.xlsx'\n",
        "excel_output_filename2 = os.path.splitext(spark_excel_filename)[0]+'_Anisotropy_TS.xlsx'\n",
        "zip_output_filename = os.path.splitext(spark_excel_filename)[0]+'_for_LCA.zip'\n",
        "print('\\nReading the Excel file and generating a CSV file...')\n",
        "print('\\nNew CSV file: \\\"'+csv_output_filename+'\\\" will be saved.')\n",
        "print('New Excel file: \\\"'+excel_output_filename+'\\\" will be saved.')\n",
        "print('New Excel file: \\\"'+excel_output_filename2+'\\\" will be saved.')\n",
        "print('New ZIP file: \\\"'+zip_output_filename+'\\\" will be saved.')\n",
        "\n",
        "### Reading the Excel file and generating a CSV file\n",
        "read_file = pd.read_excel(spark_excel_filename, header=None, index_col=False)\n",
        "read_file.to_csv(csv_output_filename, index=None, header=False)\n",
        "\n",
        "### Finding rows containing each data set\n",
        "print('\\nChecking the structure of the data file...')\n",
        "\n",
        "def logic_ds(skip_row_number):\n",
        "\tif skip_row_number >= startline and skip_row_number <= endline:\n",
        "\t\treturn False\n",
        "\treturn True\n",
        "\n",
        "f = open(csv_output_filename, \"r\", encoding=\"utf-8\")\n",
        "foo_txt = f.read()\n",
        "f.close()\n",
        "line_no = 0\n",
        "for line in foo_txt.splitlines():\n",
        "\tline_no += 1\n",
        "\tif \"Label 1 [mP]\" in line:\n",
        "\t\tL1A = line_no\n",
        "\tif \"Rawdata (perpendicular)\" in line:\n",
        "\t\tL2A = line_no\n",
        "\tif \"Rawdata (parallel)\" in line:\n",
        "\t\tL3A = line_no\n",
        "\tif \"Anisotropy\" in line:\n",
        "\t\tL4A = line_no\n",
        "\tif \"Total Intensity\" in line:\n",
        "\t\tL5A = line_no\n",
        "\tif \"Intensity (parallel)\" in line:\n",
        "\t\tL6A = line_no\n",
        "\tif \"Intensity (perpendicular)\" in line:\n",
        "\t\tL7A = line_no\n",
        "\tif \"Start Time,,,,\" in line:\n",
        "\t\tstart_dt_str = line[14:33]\n",
        "\t\tstart_dt = datetime.strptime(start_dt_str, '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "abn = L2A - L1A - 3\n",
        "\n",
        "### Extracting data from Excel/CSV and generating Pandas dataframes\n",
        "print('\\nGenerating Pandas dataframes...')\n",
        "\n",
        "##### Defining dataframes\n",
        "Polarization_mP_df = pd.DataFrame()\n",
        "Rawdata_perpendicular_df = pd.DataFrame()\n",
        "Rawdata_parallel_df = pd.DataFrame()\n",
        "Anisotropy_df = pd.DataFrame()\n",
        "Total_Intensity_df = pd.DataFrame()\n",
        "Intensity_parallel_df = pd.DataFrame()\n",
        "Intensity_perpendicular_df = pd.DataFrame()\n",
        "\n",
        "listofdfs = [\n",
        "\t\t[ 'Polarization_mP_df', L1A ],\n",
        "\t\t[ 'Rawdata_perpendicular_df', L2A ],\n",
        "\t\t[ 'Rawdata_parallel_df', L3A ],\n",
        "\t\t[ 'Anisotropy_df', L4A ],\n",
        "\t\t[ 'Total_Intensity_df', L5A ],\n",
        "\t\t[ 'Intensity_parallel_df', L6A ],\n",
        "\t\t[ 'Intensity_perpendicular_df', L7A ]\n",
        "\t\t]\n",
        "\n",
        "##### Extracting the data to each dataframe\n",
        "for i in range(7):\n",
        "\tdfname = listofdfs[i][0]\n",
        "\tstartline = listofdfs[i][1]\n",
        "\tendline = listofdfs[i][1] + abn\n",
        "\tprint(dfname, startline, endline)\n",
        "\tlocals()[dfname] = pd.read_csv(csvdatafile, delimiter=',', index_col=False, skiprows = lambda x: logic_ds(x) )\n",
        "\tif i == 0:\n",
        "\t\tcycleno = locals()[dfname]['Cycle Nr.']\n",
        "\t\ttimesec = locals()[dfname]['Time [s]']\n",
        "\t\ttmpdc = locals()[dfname]['Temp. [°C]']\n",
        "\t\ttimemin = locals()[dfname]['Time [s]'] / 60\n",
        "\t\ttimehours = locals()[dfname]['Time [s]'] / 3600\n",
        "\t\ttimedays = locals()[dfname]['Time [s]'] / 86400\n",
        "\t\tspark_dt = start_dt  +  pd.to_timedelta(timesec.astype(int), unit='s')\n",
        "\tlocals()[dfname].insert(loc=1, column='DateTime', value=spark_dt)\n",
        "\tlocals()[dfname].insert(loc=2, column='Time [hours]', value=timehours)\n",
        "\tlocals()[dfname].insert(loc=4, column='Time [m]', value=timemin)\n",
        "\tlocals()[dfname].insert(loc=5, column='Time [h]', value=timehours)\n",
        "\tlocals()[dfname].insert(loc=6, column='Time [days]', value=timedays)\n",
        "\n",
        "### Generating a dataframe for time and temp.\n",
        "Time_and_Temp_df = pd.DataFrame()\n",
        "Time_and_Temp_df['Cycle Nr.'] = cycleno\n",
        "Time_and_Temp_df['DateTime'] = spark_dt\n",
        "Time_and_Temp_df['Time [hours]'] = timehours\n",
        "Time_and_Temp_df['Time [s]'] = timesec\n",
        "Time_and_Temp_df['Time [m]'] = timemin\n",
        "Time_and_Temp_df['Time [h]'] = timehours\n",
        "Time_and_Temp_df['Time [days]'] = timedays\n",
        "Time_and_Temp_df['Temp. [°C]'] = tmpdc\n",
        "\n",
        "### Extracting columns containing data\n",
        "print('\\nExtracting columns containing data...')\n",
        "Polarization_mP_df2 = Polarization_mP_df.dropna(axis=1,how='all')\n",
        "list_of_valid_columns = Polarization_mP_df2.columns.tolist()\n",
        "Rawdata_perpendicular_df2 = Rawdata_perpendicular_df.loc[:, list_of_valid_columns]\n",
        "Rawdata_parallel_df2 = Rawdata_parallel_df.loc[:, list_of_valid_columns]\n",
        "Anisotropy_df2 = Anisotropy_df.loc[:, list_of_valid_columns]\n",
        "Total_Intensity_df2 = Total_Intensity_df.loc[:, list_of_valid_columns]\n",
        "Intensity_parallel_df2 = Intensity_parallel_df.loc[:, list_of_valid_columns]\n",
        "Intensity_perpendicular_df2 = Intensity_perpendicular_df.loc[:, list_of_valid_columns]\n",
        "\n",
        "### Calculating polarization with g-factor\n",
        "#print('\\nCalculating polarization with G-factor...')\n",
        "#Polarization_mP_float_df = pd.DataFrame(columns=list_of_valid_columns)\n",
        "#Polarization_mP_float_df['Cycle Nr.'] = cycleno\n",
        "#Polarization_mP_float_df['DateTime'] = spark_dt\n",
        "#Polarization_mP_float_df['Time [hours]'] = timehours\n",
        "#Polarization_mP_float_df['Time [s]'] = timesec\n",
        "#Polarization_mP_float_df['Time [m]'] = timemin\n",
        "#Polarization_mP_float_df['Time [h]'] = timehours\n",
        "#Polarization_mP_float_df['Time [days]'] = timedays\n",
        "#Polarization_mP_float_df['Temp. [°C]'] = tmpdc\n",
        "#g_factor = G_factor\n",
        "#i = 8\n",
        "#while i < len(list_of_valid_columns):\n",
        "# \tcolname = list_of_valid_columns[i]\n",
        "# \ti_para = Intensity_parallel_df[colname]\n",
        "# \ti_perp = Intensity_perpendicular_df[colname]\n",
        "# \tPolarization_mP_float_df[colname] = 1000 * ( ( i_para - i_perp ) / ( i_para  + g_factor * i_perp ) )\n",
        "# \ti += 1\n",
        "\n",
        "### Calculating polarization and anisotropy with g-factor\n",
        "print('\\nCalculating polarization and anisotropy with G-factor...')\n",
        "\n",
        "Polarization_mP_float_df = pd.DataFrame(columns=list_of_valid_columns)\n",
        "Polarization_mP_float_df['Cycle Nr.'] = cycleno\n",
        "Polarization_mP_float_df['DateTime'] = spark_dt\n",
        "Polarization_mP_float_df['Time [hours]'] = timehours\n",
        "Polarization_mP_float_df['Time [s]'] = timesec\n",
        "Polarization_mP_float_df['Time [m]'] = timemin\n",
        "Polarization_mP_float_df['Time [h]'] = timehours\n",
        "Polarization_mP_float_df['Time [days]'] = timedays\n",
        "Polarization_mP_float_df['Temp. [°C]'] = tmpdc\n",
        "\n",
        "Anisotropy_float_df = pd.DataFrame(columns=list_of_valid_columns)\n",
        "Anisotropy_float_df['Cycle Nr.'] = cycleno\n",
        "Anisotropy_float_df['DateTime'] = spark_dt\n",
        "Anisotropy_float_df['Time [hours]'] = timehours\n",
        "Anisotropy_float_df['Time [s]'] = timesec\n",
        "Anisotropy_float_df['Time [m]'] = timemin\n",
        "Anisotropy_float_df['Time [h]'] = timehours\n",
        "Anisotropy_float_df['Time [days]'] = timedays\n",
        "Anisotropy_float_df['Temp. [°C]'] = tmpdc\n",
        "no_of_time_points = len(cycleno)\n",
        "g_factor = G_factor\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\ti_para = Rawdata_parallel_df[colname].to_numpy()\n",
        "\ti_perp = Rawdata_perpendicular_df[colname].to_numpy()\n",
        "\t# print(i_para)\n",
        "\t# print(i_perp)\n",
        "\tj = 0\n",
        "\tnvar = None\n",
        "\tPolarization_X = []\n",
        "\tAnisotropy_X = []\n",
        "\twhile j < no_of_time_points:\n",
        "\t\tif i_para[j] == \"OVER\" or i_perp[j] == \"OVER\":\n",
        "\t\t\tpv = nvar\n",
        "\t\t\tav = nvar\n",
        "\t\telse:\n",
        "\t\t\ti_paraj = int(i_para[j])\n",
        "\t\t\ti_perpj = int(i_perp[j])\n",
        "\t\t\tpv = 1000 * ( ( i_paraj - i_perpj ) / ( i_paraj  + g_factor * i_perpj ) )\n",
        "\t\t\tav = 1000 * ( ( i_paraj - i_perpj ) / ( i_paraj  + 2 * g_factor * i_perpj ) )\n",
        "\t\t# print(colname + ', ' + str(j) + ', ' + str(pv) + ', ' + str(av))\n",
        "\t\tPolarization_X.append(pv)\n",
        "\t\tAnisotropy_X.append(av)\n",
        "\t\tj += 1\n",
        "\tPolarization_mP_float_df[colname] = Polarization_X\n",
        "\tAnisotropy_float_df[colname] = Anisotropy_X\n",
        "\ti += 1\n",
        "\n",
        "number_of_rows = len(Anisotropy_float_df.index)\n",
        "last_row_index = number_of_rows - 1\n",
        "total_time = Anisotropy_float_df.loc[last_row_index]['Time [s]'] - Anisotropy_float_df.loc[0]['Time [s]']\n",
        "total_time_in_min = total_time * (1/60)\n",
        "total_time_in_hours = total_time * (1/(60*60))\n",
        "total_time_in_days = total_time * (1/(24*60*60))\n",
        "time_interval = total_time_in_hours / last_row_index\n",
        "time_interval2 = round(time_interval, 12)\n",
        "print('Number of rows: ' + str(number_of_rows))\n",
        "print('First time points: ' + str(Anisotropy_float_df.loc[0]['Time [s]']) + ' sec')\n",
        "print('Last time points: ' + str(Anisotropy_float_df.loc[last_row_index]['Time [s]']) + ' sec')\n",
        "print('Total time duration: ' + str(total_time) + ' sec = ' + str(total_time_in_min) + ' min = ' + str(total_time_in_hours) + ' hours = ' + str(total_time_in_days) + ' days')\n",
        "print('Time interval: ' + str(time_interval) + ' h')\n",
        "print('Time interval: ' + str(time_interval2) + ' h')\n",
        "excel2_sheet_name = 'Every '+str('{:.12f}'.format(time_interval2))+' h'\n",
        "\n",
        "Anisotropy_float_df2= Anisotropy_float_df.iloc[:,8:len(list_of_valid_columns)+1]\n",
        "with pd.ExcelWriter(excel_output_filename2) as writer:\n",
        "\tAnisotropy_float_df2.to_excel(writer, sheet_name=excel2_sheet_name, index=None, header=True)\n",
        "\n",
        "listofdf2s = [ 'Time_and_Temp_df',\n",
        "\t\t'Polarization_mP_df2',\n",
        "\t\t'Rawdata_perpendicular_df2',\n",
        "\t\t'Rawdata_parallel_df2',\n",
        "\t\t'Anisotropy_df2',\n",
        "\t\t'Total_Intensity_df2',\n",
        "\t\t'Intensity_parallel_df2',\n",
        "\t\t'Intensity_perpendicular_df2',\n",
        "\t\t'Polarization_mP_float_df',\n",
        "\t\t'Anisotropy_float_df' ]\n",
        "\n",
        "for i in range(10):\n",
        "\tdf2name = listofdf2s[i]\n",
        "\t# print('\\n'+df2name)\n",
        "\t# print(locals()[df2name])\n",
        "\n",
        "\n",
        "if Plotting_data == \"Yes\":\n",
        "\ti = 8\n",
        "\twhile i < len(list_of_valid_columns):\n",
        "\t\twell_to_plot = list_of_valid_columns[i]\n",
        "\t\tplt.figure(figsize=(10, 4))\n",
        "\t\tplt.plot(Anisotropy_float_df['Time [hours]'], Anisotropy_float_df[well_to_plot])\n",
        "\t\tplt.xlabel('Time (hours)')\n",
        "\t\tplt.ylabel('Fluorescence Anisotropy (mA)')\n",
        "\t\tplt.title(f'Anisotropy: Well {well_to_plot}')\n",
        "\t\tplt.grid(True)\n",
        "\t\tplt.show()\n",
        "\t\ti += 1\n",
        "\n",
        "### Generating a new Excel file having multiple sheets\n",
        "print('\\nPreparing a new Excel file to save pre-processed data...')\n",
        "print('It will take 2-3 min. Wait a while, please.')\n",
        "\n",
        "##### Generating a worksheet for the note\n",
        "wells = ''\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\t# if len(colname) == 2:\n",
        "\t# \twells = wells + colname[:1] + '0' + colname[1:]\n",
        "\t# if len(colname) == 3:\n",
        "\t# \twells = wells + colname\n",
        "\twells = wells + colname\n",
        "\tif i < len(list_of_valid_columns) - 1:\n",
        "\t\twells = wells + ', '\n",
        "\ti += 1\n",
        "\n",
        "note_df = pd.DataFrame.from_dict(\n",
        "\t\t{'A': ['Original Data Filename', 'Processed Date and Time (UTC)', 'G-factor', 'Sample Wells'],\n",
        "\t\t 'B': ['', '', '', ''],\n",
        "\t\t 'C': ['', '', '', ''],\n",
        "\t\t 'D': ['', '', '', ''],\n",
        "\t\t 'E': [spark_excel_filename, processed_dnt_str, g_factor, wells]\n",
        "\t\t })\n",
        "\n",
        "##### Writting the data to the new Excel file\n",
        "with pd.ExcelWriter(excel_output_filename) as writer:\n",
        "\tread_file.to_excel(writer, sheet_name='Spark Datasheet', index=None, header=False)\n",
        "\tnote_df.to_excel(writer, sheet_name='Note', index=None, header=False)\n",
        "\tTime_and_Temp_df.to_excel(writer, sheet_name='Time and Temp')\n",
        "\tPolarization_mP_df2.to_excel(writer, sheet_name='Polarization (mP)')\n",
        "\tRawdata_perpendicular_df2.to_excel(writer, sheet_name='Rawdata Perpendicular')\n",
        "\tRawdata_parallel_df2.to_excel(writer, sheet_name='Rawdata Parallel')\n",
        "\tAnisotropy_df2.to_excel(writer, sheet_name='Anisotropy')\n",
        "\tTotal_Intensity_df2.to_excel(writer, sheet_name='Total Intensity')\n",
        "\tIntensity_parallel_df2.to_excel(writer, sheet_name='Intensity Parallel')\n",
        "\tIntensity_perpendicular_df2.to_excel(writer, sheet_name='Intensity Perpendicular')\n",
        "\tPolarization_mP_float_df.to_excel(writer, sheet_name='Polarization corr by G factor')\n",
        "\tAnisotropy_float_df.to_excel(writer, sheet_name='Anisotropy corr by G factor')\n",
        "\n",
        "### Generating data files for LumiCycle Analysis\n",
        "print('\\nPreparing an anisotropy data file (readable with LumiCycle Analysis) for each well...')\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\tif len(colname) == 2:\n",
        "\t\toutputdatfilename = colname[:1] + '0' + colname[1:] + '.dat'\n",
        "\tif len(colname) == 3:\n",
        "\t\toutputdatfilename = colname + '.dat'\n",
        "\tAnisotropy_float_df.to_csv(outputdatfilename, header=False, index=False, sep ='\\t', columns=['Time [days]',colname])\n",
        "\tprint(outputdatfilename)\n",
        "\ti += 1\n",
        "\n",
        "##### Packing the .dat files into a zip file\n",
        "print('\\nPacking the .dat files into a zip file...')\n",
        "!zip -r {zip_output_filename} ./*.dat\n",
        "\n",
        "### Downloading the CSV, Excel, and ZIP files into the local host\n",
        "files.download(csv_output_filename)\n",
        "files.download(excel_output_filename)\n",
        "files.download(excel_output_filename2)\n",
        "files.download(zip_output_filename)\n",
        "\n",
        "print('\\nDownloading the CSV, Excel, and Zip files into \\\"Downloads\\\" folder in your computer...')\n",
        "\n",
        "endtime = datetime.now(timezone.utc)\n",
        "td_m = endtime - sttime\n",
        "processed_dnt_str = endtime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print('\\nElapse time: '+str(td_m.seconds)+' seconds')\n",
        "print('\\nCompleted at '+processed_dnt_str+' (UTC)\\n')\n",
        "\n",
        "### End of script"
      ]
    }
  ]
}