{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNumP5+++iiPy8pKE6pl8MM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxda6216/SPARK_fluorescence_anisotropy/blob/main/SPARK_fluorescence_anisotropy_data_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r38FHIEAD1dM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "###\n",
        "### This script is to pre-process a SPARK fluorescence anisotropy data file (Excel file) and save the resulting pre-processed data into a new Excel file.\n",
        "###\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import io\n",
        "import os\n",
        "from google.colab import files\n",
        "# import csv\n",
        "# import math\n",
        "# import numpy as np\n",
        "# from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
        "# import matplotlib.pyplot as plt\n",
        "# from matplotlib.backends.backend_pdf import PdfPages \n",
        "# from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "#@markdown **This script is to pre-process a SPARK fluorescence anisotropy data file (Excel file) and save the resulting pre-processed data into a new Excel file.**\n",
        "\n",
        "#@markdown - [GitHub repository page](https://github.com/dxda6216/SPARK_fluorescence_anisotropy)\n",
        "\n",
        "G_factor = 1.000 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown 1. Input G-factor\n",
        "#@markdown 2. **Runtime** -> **Restart and run all** (or press **Ctrl+M** and then press **Ctrl+F9**)\n",
        "#@markdown 3. Wait until `Choose Files` or `Browse...` button appears below.\n",
        "#@markdown 4. Click `Choose Files` or `Browse...` button and select a SPARK Excel data file in your computer.\n",
        "#@markdown 5. Wait a while. An Excel file will be saved in \"Downloads\" folder in your computer.\n",
        "\n",
        "### Deleting old files\n",
        "!rm -f *.xlsx *.csv *.dat *.zip\n",
        "\n",
        "### Uploading an Excel data file\n",
        "uploaded = files.upload()\n",
        "\n",
        "sttime = datetime.now(timezone.utc)\n",
        "processed_dnt_str = sttime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print('\\nStarted at '+processed_dnt_str+' (UTC)')\n",
        "\n",
        "spark_excel_filename = next(iter(uploaded))\n",
        "print('\\n\\\"'+spark_excel_filename+'\\\" has been uploaded.')\n",
        "csv_output_filename = os.path.splitext(spark_excel_filename)[0]+'.csv'\n",
        "csvdatafile = csv_output_filename\n",
        "excel_output_filename = os.path.splitext(spark_excel_filename)[0]+'_SPLITTED.xlsx'\n",
        "zip_output_filename = os.path.splitext(spark_excel_filename)[0]+'_for_LCA.zip'\n",
        "print('\\nReading the Excel file and generating a CSV file...')\n",
        "print('\\nNew CSV file: \\\"'+csv_output_filename+'\\\" will be saved.')\n",
        "print('New Excel file: \\\"'+excel_output_filename+'\\\" will be saved.')\n",
        "print('New ZIP file: \\\"'+zip_output_filename+'\\\" will be saved.')\n",
        "\n",
        "### Reading the Excel file and generating a CSV file\n",
        "read_file = pd.read_excel(spark_excel_filename)\n",
        "read_file.to_csv(csv_output_filename, index=None, header=False)\n",
        "\n",
        "### Finding rows containing each data set\n",
        "print('\\nChecking the structure of the data file...')\n",
        "\n",
        "def logic_ds(skip_row_number):\n",
        "\tif skip_row_number >= startline and skip_row_number <= endline:\n",
        "\t\treturn False\n",
        "\treturn True\n",
        "\t\n",
        "f = open(csv_output_filename, \"r\", encoding=\"utf-8\")\n",
        "foo_txt = f.read()\n",
        "f.close()\n",
        "line_no = 0\n",
        "for line in foo_txt.splitlines():\n",
        "\tline_no += 1\n",
        "\tif \"Label 1 [mP]\" in line:\n",
        "\t\tL1A = line_no\n",
        "\tif \"Rawdata (perpendicular)\" in line:\n",
        "\t\tL2A = line_no\n",
        "\tif \"Rawdata (parallel)\" in line:\n",
        "\t\tL3A = line_no\n",
        "\tif \"Anisotropy\" in line:\n",
        "\t\tL4A = line_no\n",
        "\tif \"Total Intensity\" in line:\n",
        "\t\tL5A = line_no\n",
        "\tif \"Intensity (parallel)\" in line:\n",
        "\t\tL6A = line_no\n",
        "\tif \"Intensity (perpendicular)\" in line:\n",
        "\t\tL7A = line_no\n",
        "\tif \"Start Time,,,,\" in line:\n",
        "\t\tstart_dt_str = line[14:33]\n",
        "\t\tstart_dt = datetime.strptime(start_dt_str, '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "abn = L2A - L1A - 3\n",
        "\n",
        "### Extracting data from Excel/CSV and generating Pandas dataframes\n",
        "print('\\nGenerating Pandas dataframes...')\n",
        "\n",
        "listofdfs = [\n",
        "\t\t[ 'Polarization_mP_df', L1A ], \n",
        "\t\t[ 'Rawdata_perpendicular_df', L2A ], \n",
        "\t\t[ 'Rawdata_parallel_df', L3A ], \n",
        "\t\t[ 'Anisotropy_df', L4A ], \n",
        "\t\t[ 'Total_Intensity_df', L5A ], \n",
        "\t\t[ 'Intensity_parallel_df', L6A ], \n",
        "\t\t[ 'Intensity_perpendicular_df', L7A ]\n",
        "\t\t]\n",
        "\n",
        "for i in range(7):\n",
        "\tdfname = listofdfs[i][0]\n",
        "\tstartline = listofdfs[i][1]\n",
        "\tendline = listofdfs[i][1] + abn\n",
        "\tprint(dfname, startline, endline)\n",
        "\tlocals()[dfname] = pd.DataFrame()\n",
        "\tlocals()[dfname] = pd.read_csv(csvdatafile, delimiter=',', index_col=False, skiprows = lambda x: logic_ds(x) )\n",
        "\tif i == 0:\n",
        "\t\tcycleno = locals()[dfname]['Cycle Nr.']\n",
        "\t\ttimesec = locals()[dfname]['Time [s]']\n",
        "\t\ttmpdc = locals()[dfname]['Temp. [째C]']\n",
        "\t\ttimemin = locals()[dfname]['Time [s]'] / 60\n",
        "\t\ttimehours = locals()[dfname]['Time [s]'] / 3600\n",
        "\t\ttimedays = locals()[dfname]['Time [s]'] / 86400\n",
        "\t\tspark_dt = start_dt  +  pd.to_timedelta(timesec.astype(int), unit='s')\n",
        "\tlocals()[dfname].insert(loc=1, column='DateTime', value=spark_dt)\n",
        "\tlocals()[dfname].insert(loc=2, column='Time [hours]', value=timehours)\n",
        "\tlocals()[dfname].insert(loc=4, column='Time [m]', value=timemin)\n",
        "\tlocals()[dfname].insert(loc=5, column='Time [h]', value=timehours)\n",
        "\tlocals()[dfname].insert(loc=6, column='Time [days]', value=timedays)\n",
        "\n",
        "### Generating a dataframe for time and temp.\n",
        "Time_and_Temp_df = pd.DataFrame()\n",
        "Time_and_Temp_df['Cycle Nr.'] = cycleno\n",
        "Time_and_Temp_df['DateTime'] = spark_dt\n",
        "Time_and_Temp_df['Time [hours]'] = timehours\n",
        "Time_and_Temp_df['Time [s]'] = timesec\n",
        "Time_and_Temp_df['Time [m]'] = timemin\n",
        "Time_and_Temp_df['Time [h]'] = timehours\n",
        "Time_and_Temp_df['Time [days]'] = timedays\n",
        "Time_and_Temp_df['Temp. [째C]'] = tmpdc\n",
        "\n",
        "### Extracting columns containing data\n",
        "print('\\nExtracting columns containing data...')\n",
        "Polarization_mP_df2 = Polarization_mP_df.dropna(axis=1,how='all')\n",
        "list_of_valid_columns = Polarization_mP_df2.columns.tolist()\n",
        "Rawdata_perpendicular_df2 = Rawdata_perpendicular_df.loc[:, list_of_valid_columns]\n",
        "Rawdata_parallel_df2 = Rawdata_parallel_df.loc[:, list_of_valid_columns]\n",
        "Anisotropy_df2 = Anisotropy_df.loc[:, list_of_valid_columns]\n",
        "Total_Intensity_df2 = Total_Intensity_df.loc[:, list_of_valid_columns]\n",
        "Intensity_parallel_df2 = Intensity_parallel_df.loc[:, list_of_valid_columns]\n",
        "Intensity_perpendicular_df2 = Intensity_perpendicular_df.loc[:, list_of_valid_columns]\n",
        "\n",
        "### Calculating polarization with g-factor\n",
        "print('\\nCalculating polarization with G-factor...')\n",
        "Polarization_mP_float_df = pd.DataFrame(columns=list_of_valid_columns)\n",
        "Polarization_mP_float_df['Cycle Nr.'] = cycleno\n",
        "Polarization_mP_float_df['DateTime'] = spark_dt\n",
        "Polarization_mP_float_df['Time [hours]'] = timehours\n",
        "Polarization_mP_float_df['Time [s]'] = timesec\n",
        "Polarization_mP_float_df['Time [m]'] = timemin\n",
        "Polarization_mP_float_df['Time [h]'] = timehours\n",
        "Polarization_mP_float_df['Time [days]'] = timedays\n",
        "Polarization_mP_float_df['Temp. [째C]'] = tmpdc\n",
        "g_factor = G_factor\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\ti_para = Intensity_parallel_df[colname]\n",
        "\ti_perp = Intensity_perpendicular_df[colname]\n",
        "\tPolarization_mP_float_df[colname] = 1000 * ( ( i_para - i_perp ) / ( i_para  + g_factor * i_perp ) )\n",
        "\ti += 1\n",
        "\n",
        "### Calculating anisotropy with g-factor\n",
        "print('\\nCalculating anisotropy with G-factor...')\n",
        "Anisotropy_float_df = pd.DataFrame(columns=list_of_valid_columns)\n",
        "Anisotropy_float_df['Cycle Nr.'] = cycleno\n",
        "Anisotropy_float_df['DateTime'] = spark_dt\n",
        "Anisotropy_float_df['Time [hours]'] = timehours\n",
        "Anisotropy_float_df['Time [s]'] = timesec\n",
        "Anisotropy_float_df['Time [m]'] = timemin\n",
        "Anisotropy_float_df['Time [h]'] = timehours\n",
        "Anisotropy_float_df['Time [days]'] = timedays\n",
        "Anisotropy_float_df['Temp. [째C]'] = tmpdc\n",
        "g_factor = G_factor\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\ti_para = Intensity_parallel_df[colname]\n",
        "\ti_perp = Intensity_perpendicular_df[colname]\n",
        "\tAnisotropy_float_df[colname] = 1000 * ( ( i_para - i_perp ) / ( i_para  + 2 * g_factor * i_perp ) )\n",
        "\ti += 1\n",
        "\n",
        "listofdf2s = [ 'Time_and_Temp_df', \n",
        "\t\t'Polarization_mP_df2', \n",
        "\t\t'Rawdata_perpendicular_df2', \n",
        "\t\t'Rawdata_parallel_df2', \n",
        "\t\t'Anisotropy_df2', \n",
        "\t\t'Total_Intensity_df2', \n",
        "\t\t'Intensity_parallel_df2', \n",
        "\t\t'Intensity_perpendicular_df2', \n",
        "\t\t'Polarization_mP_float_df', \n",
        "\t\t'Anisotropy_float_df' ]\n",
        "\n",
        "for i in range(10):\n",
        "\tdf2name = listofdf2s[i]\n",
        "\tprint('\\n'+df2name)\n",
        "\tprint(locals()[df2name])\n",
        "\n",
        "### Generating a new Excel file having multiple sheets \n",
        "print('\\nPreparing a new Excel file to save pre-processed data...')\n",
        "print('It will take 2-3 min. Wait a while, please.')\n",
        "\n",
        "##### Generating a worksheet for the note\n",
        "wells = ''\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\t# if len(colname) == 2:\n",
        "\t# \twells = wells + colname[:1] + '0' + colname[1:]\n",
        "\t# if len(colname) == 3:\n",
        "\t# \twells = wells + colname\n",
        "\twells = wells + colname\n",
        "\tif i < len(list_of_valid_columns) - 1:\n",
        "\t\twells = wells + ', '\n",
        "\ti += 1\n",
        "\n",
        "note_df = pd.DataFrame.from_dict(\n",
        "\t\t{'A': ['Original Data Filename', 'Processed Date and Time (UTC)', 'G-factor', 'Sample Wells'], \n",
        "\t\t 'B': ['', '', '', ''], \n",
        "\t\t 'C': ['', '', '', ''], \n",
        "\t\t 'D': ['', '', '', ''], \n",
        "\t\t 'E': [spark_excel_filename, processed_dnt_str, g_factor, wells]\n",
        "\t\t })\n",
        "\n",
        "##### Writting the data to the new Excel file\n",
        "with pd.ExcelWriter(excel_output_filename) as writer:\n",
        "\tread_file.to_excel(writer, sheet_name='Spark Datasheet', index = None, header=False)\n",
        "\tnote_df.to_excel(writer, sheet_name='Note', index = None, header=False)\t\n",
        "\tTime_and_Temp_df.to_excel(writer, sheet_name='Time and Temp')\n",
        "\tPolarization_mP_df2.to_excel(writer, sheet_name='Polarization (mP)')\n",
        "\tRawdata_perpendicular_df2.to_excel(writer, sheet_name='Rawdata Perpendicular')\n",
        "\tRawdata_parallel_df2.to_excel(writer, sheet_name='Rawdata Parallel')\n",
        "\tAnisotropy_df2.to_excel(writer, sheet_name='Anisotropy')\n",
        "\tTotal_Intensity_df2.to_excel(writer, sheet_name='Total Intensity')\n",
        "\tIntensity_parallel_df2.to_excel(writer, sheet_name='Intensity Parallel')\n",
        "\tIntensity_perpendicular_df2.to_excel(writer, sheet_name='Intensity Perpendicular')\n",
        "\tPolarization_mP_float_df.to_excel(writer, sheet_name='Polarization corr by G factor')\n",
        "\tAnisotropy_float_df.to_excel(writer, sheet_name='Anisotropy corr by G factor')\n",
        "\n",
        "### Generating data files for LumiCycle Analysis\n",
        "print('\\nPreparing an anisotropy data file (readable with LumiCycle Analysis) for each well...')\n",
        "i = 8\n",
        "while i < len(list_of_valid_columns):\n",
        "\tcolname = list_of_valid_columns[i]\n",
        "\tif len(colname) == 2:\n",
        "\t\toutputdatfilename = colname[:1] + '0' + colname[1:] + '.dat'\n",
        "\tif len(colname) == 3:\n",
        "\t\toutputdatfilename = colname + '.dat'\n",
        "\tAnisotropy_float_df.to_csv(outputdatfilename, header=False, index=False, sep ='\\t', columns=['Time [days]',colname])\n",
        "\tprint(outputdatfilename)\n",
        "\ti = i + 1\n",
        "\n",
        "##### Packing the .dat files into a zip file\n",
        "print('\\nPacking the .dat files into a zip file...')\n",
        "!zip -r {zip_output_filename} ./*.dat\n",
        "\n",
        "### Downloading the CSV, Excel, and ZIP files into the local host\n",
        "files.download(csv_output_filename)\n",
        "files.download(excel_output_filename)\n",
        "files.download(zip_output_filename)\n",
        "\n",
        "print('\\nDownloading the CSV, Excel, and Zip files into \\\"Downloads\\\" folder in your computer...')\n",
        "\n",
        "endtime = datetime.now(timezone.utc)\n",
        "td_m = endtime - sttime\n",
        "processed_dnt_str = endtime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print('\\nElapse time: '+str(td_m.seconds)+' seconds')\n",
        "print('\\nCompleted at '+processed_dnt_str+' (UTC)\\n')\n",
        "\n",
        "### End of script"
      ]
    }
  ]
}